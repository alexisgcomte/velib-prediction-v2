{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tensorflow Prophet Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of librairies\n",
    "import tensorflow as tf\n",
    "import mysql.connector as mariadb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tqdm import tqdm\n",
    "from joblib import load\n",
    "\n",
    "class sql_query:\n",
    "    def __init__(self, credentials_path):\n",
    "        self.db_credentials = pd.read_csv(credentials_path, index_col=\"Field\")\n",
    "      \n",
    "    \n",
    "    def __call__(self, query):\n",
    "        \n",
    "        mariadb_connection = mariadb.connect(\n",
    "            user=self.db_credentials.loc[\"user\"][0],\n",
    "            password=self.db_credentials.loc[\"password\"][0],\n",
    "            host=self.db_credentials.loc[\"host\"][0],\n",
    "            port=3306,\n",
    "            db = \"db_velib\")\n",
    "        \n",
    "        self.cursor = mariadb_connection.cursor()\n",
    "        cursor = self.cursor\n",
    "        cursor.execute(\"SET  time_zone = 'Europe/Paris'\")\n",
    "        cursor.execute(query)\n",
    "        field_names = [i[0] for i in cursor.description]\n",
    "        df = pd.DataFrame(cursor, columns=field_names)\n",
    "        return df\n",
    "    \n",
    "# Transforming the input data in the proper format \n",
    "\n",
    "\n",
    "def measure_rmse(actual, predicted):\n",
    "    return math.sqrt(mean_squared_error(actual, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting base for prediction \n",
    "\n",
    "request = sql_query(\"../../aws_mariadb_crendentials.csv\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT station_id, date_of_update, nb_total_free_bikes FROM db_velib.velib_realtime\n",
    "WHERE date_of_update >= DATE_SUB(NOW(), INTERVAL 185 Minute) AND MINUTE(date_of_update)%5 = 0\n",
    "ORDER BY station_id, date_of_update ASC;\n",
    "\"\"\"\n",
    "df= request(query)\n",
    "df.index = df.date_of_update\n",
    "df = df[['station_id','nb_total_free_bikes']]\n",
    "df = df.pivot_table(df, index= 'station_id', columns=df.index)\n",
    "\n",
    "# Creating dataframe for proper predction\n",
    "                    \n",
    "df_prediction = pd.DataFrame(index=df.index, columns=['last_observations','Model_A', 'Model_B'])\n",
    "                    \n",
    "for i in df_prediction.index:\n",
    "    df_prediction[\"last_observations\"].loc[i] = np.array(df.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001, 1002, 1003, 1006, 1007]\n"
     ]
    }
   ],
   "source": [
    "# Extracting the list of the stations\n",
    "\n",
    "request = sql_query(\"../../aws_mariadb_crendentials.csv\")\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT station_id FROM velib_realtime\n",
    "\"\"\"\n",
    "df= request(query)\n",
    "# Removing bad values\n",
    "df= df.drop(0)\n",
    "df = df.drop(1391)\n",
    "list_of_stations = list(df.station_id)\n",
    "print(list_of_stations[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001, 1002, 1003, 1006]\n"
     ]
    }
   ],
   "source": [
    "# limiting for testing purpuse\n",
    "list_of_stations= list_of_stations[0:4]\n",
    "print(list_of_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  1001\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:02<00:02,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  1002\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  1003\n",
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:04<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished  1006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main pipelinhe\n",
    "\n",
    "# Variables\n",
    "day_of_testing = '2020-05-17'\n",
    "past_history = 36\n",
    "future_target = 6\n",
    "\n",
    "# Request for database\n",
    "\n",
    "for station_id in tqdm(list_of_stations):\n",
    "    \n",
    "    # Importing models\n",
    "\n",
    "    LSTM_model_A = tf.keras.models.load_model('/home/exalis/Github/velib-prediction-v2/4. Models/Tensorflow Univariate - {} - {} - LSTM_A.h5'.format(day_of_testing, station_id))\n",
    "    LSTM_model_B = tf.keras.models.load_model('/home/exalis/Github/velib-prediction-v2/4. Models/Tensorflow Univariate - {} - {} - LSTM_B.h5'.format(day_of_testing, station_id))\n",
    "    std = load('/home/exalis/Github/velib-prediction-v2/4. Models/Tensorflow Univariate - {} - {} - std.joblib'.format(day_of_testing, station_id)) \n",
    "    \n",
    "    \n",
    "    # Std Scaling\n",
    "    \n",
    "    input_data = std.transform(df_prediction[df_prediction.index == station_id][\"last_observations\"].iloc[0].reshape(-1, 1))[-36:]\n",
    "    # Exporting results\n",
    "    \n",
    "    df_prediction.loc[station_id]['Model_A'] = std.inverse_transform(LSTM_model_A.predict(input_data.reshape(1,past_history,1))[0])\n",
    "    df_prediction.loc[station_id]['Model_B'] = std.inverse_transform(LSTM_model_B.predict(input_data.reshape(1,past_history,1))[0])\n",
    "\n",
    "    \n",
    "   # df_results.to_csv(\"/home/exalis/Github/velib-prediction-v2/4. Models/Tensorflow Univariate Results - {} - {}.csv\".format(day_of_testing, station_id))\n",
    "    \n",
    "    \n",
    "    print('finished ', station_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
